---
title       : Hierarchical Models for RNA-seq
author      : Michael Love
framework   : revealjs
revealjs: # https://github.com/hakimel/reveal.js/
  transition  : linear
  theme       : serif
  center      : "true"
highlighter : highlight.js
hitheme     : tomorrow
widgets     : [mathjax]
mode        : selfcontained
knit        : slidify::knit2slides
---

### Hierarchical Modeling for RNA-seq

Michael Love

Dept of Biostatistics

Dept of Genetics

---

### DNA => RNA

<img src="img/tx_elong.png">

<img src="img/tx_em.jpg">

---

### Why measure RNA: 
### molecular phenotype

<img width=500 src="img/people.jpg">

---

### Why measure RNA: 
### tissue diversity

<img src="img/roadmap.jpg">

<small>[Roadmap Epigenomics](http://www.roadmapepigenomics.org)</small>

---

### Why measure RNA: 
### tissue diversity

<img width=500 src="img/gtex.png">

<small>[GTEx](http://www.gtexportal.org/home/)</small>

---

### Why measure RNA:
### within tissue over time

<img src="img/circ.png">

<small>[Zhang, et al. Circadian gene expression atlas (2014)](http://www.pnas.org/content/111/45/16219.full)</small>

---

### Why measure RNA: 
### discover disease sub-types

<img width=400 src="img/perou.png">

<small>[Perou, et al. Molecular portraits of human breast tumours (2000)](http://www.nature.com/nature/journal/v406/n6797/full/406747a0.html)</small>

---

### Step back: pre-sequencing

* Before sequencing was microarray
* Signal was captured light (positive, "continuous")

<img width=350 src="img/ma2.png"> <img width=300 src="img/ma.jpg">


---

### Motivating problem

* Gene expression for *i*=1,...,N genes and *j*=1,...,M samples
* log of gene expression values are in a tall matrix X
* log here is convenient because gene expression is non-negative and has a
  long tail
* 2 equal sized groups of samples A and B

<br>

$$
\begin{align}
X_{ij} &\sim N(\mu_{ij}, \sigma_i) \\
\mu_{ij} &= \mu_{i0}, \quad j \in A \\
\mu_{ij} &= \mu_{i0} + \delta_i, \quad j \in B
\end{align}
$$

<br>

$\delta_i \ne 0$ implies DE (differential expression)

---

### Note $\sigma_i$

This is *critical*: different genes *i* have different amount of variability.

<br>

$$ 
\begin{align}
X_{ij} &\sim N(\mu_{ij}, \sigma_i) \\
\mu_{ij} &= \mu_{i0}, \quad j \in A \\
\mu_{ij} &= \mu_{i0} + \delta_i, \quad j \in B
\end{align}
$$

---

### Goal of differential expression testing

* Find a set of genes for which $\delta_i \ne 0$
* And which obeys false discovery rate bounds
* For G genes in our set at FDR threshold z

<br>

$$
E(\sum_i 1_{ \{\delta_i = 0\} }) \le G z
$$

---

### Is this realistic?

* Can we accomplish this if all $\delta_i \ne 0$
  - no, because methods rely on computational normalization
* Are any $\delta_i = 0$? 
  - maybe not, but many are very small for controlled experiment

---

### Is this realistic?

* What about $\sigma_i$ for both groups?
  - often this is enough, larger variance dominates
  - not for single cell experiments
* More complex parametric models: [baySeq](bioconductor.org/packages/baySeq)
* Non-parametric: [SAM / SAMseq](http://statweb.stanford.edu/~tibs/SAM/)

---

### Back to the model

$$
\begin{align}
X_{ij} &\sim N(\mu_{ij}, \sigma_i) \\
\mu_{ij} &= \mu_{i0}, \quad j \in A \\
\mu_{ij} &= \mu_{i0} + \delta_i, \quad j \in B
\end{align}
$$

<br>

* N = 5000, M = 6
* $\delta_i = 0$ for 90%
* $\delta_i = \pm1$ for 10%
* $\sigma_i \sim \Gamma(5,10)$ 

---

### Distribution of $\sigma_i$

```{r sigmadist, echo=FALSE}
M <- 6
N <- 5000
mu0 <- rep(0, N)
mu1 <- delta <- sample(c(0,1,-1), N, TRUE, prob=c(.9,.05,.05))
sigma <- rgamma(N,5,10)
library(rafalib)
bigpar()
hist(sigma, xlab=expression(sigma[i]),
     col="grey", border="white", main="")
```

---

### Try simple row t-tests

```{r boxt, echo=FALSE}
X <- matrix(rnorm(N*M,
                  c(rep(mu0,M/2),rep(mu1,M/2)),
                  sigma),ncol=M)
library(genefilter)
cond <- factor(rep(2:1, each=M/2))
ts <- rowttests(X, cond)
bigpar()
boxplot(ts$statistic ~ delta,
        xlab=expression(delta[i]),
        ylab=expression(t[i]))
```

---

### Just looking at ranks

```{r roc, echo=FALSE}
abs.t <- abs(ts$statistic)
tseq <- seq(from=0,to=max(abs.t),length=400)
curve <- function(rank) {
  res <- t(sapply(tseq, function(t) {
    fdr <- mean(delta[rank >= t] == 0)
    sens <- mean(rank[delta != 0] > t)
    c(FDR=fdr, sensitivity=sens)
  }))
}
bigpar()
plot(curve(abs.t), type="o", pch=16, xlim=c(0,1), ylim=c(0,1))
lines(curve(sample(abs.t,N)), type="o", pch=16, col="grey")
```

---

### Characterize the false positives

Call $\textrm{med}(t) \equiv \textrm{median}( \left| t_i \right| )$ for $i$ s.t. $\delta_i \ne 0$

```{r mediant, echo=FALSE}
med.t <- median(abs.t[delta != 0])
bigpar()
boxplot(abs(ts$statistic) ~ abs(delta),
        xlab=expression(abs(delta[i])),
        ylab=expression(abs(t[i])))
abline(h=med.t,col="red")
```

---

### Estimates of $\sigma_i$

$\textrm{med}(t) \equiv \textrm{median}( \left| t_i \right| )$ for $i$ s.t. $\delta_i \ne 0$

```{r fp, echo=FALSE, fig.width=12}
sigma.hat <- ts$dm / (ts$statistic * sqrt(4/M))
transgrey <- rgb(.2,.2,.2,.2)
bigpar(1,2)
plot(sigma, sigma.hat, main="all genes",
     xlab=expression(sigma[i]), ylab=expression(hat(sigma[i])),
     col=ifelse(delta != 0, "dodgerblue", transgrey))
legend("topright",c("null","DE"),pch=1,
       col=c("grey","dodgerblue"),cex=2,bg="white")
plot(sigma[delta == 0], sigma.hat[delta == 0],
     main="null genes",
     xlab=expression(sigma[i]), ylab=expression(hat(sigma[i])),
     col=ifelse(abs.t[delta == 0] > med.t, "red", transgrey))
legend("topright",c(expression(abs(t[i])<med(t)),expression(abs(t[i])>med(t))),pch=1,
       col=c("grey","red"),cex=2,bg="white")
```

---

### New estimator for $\sigma_i$

$\bar{\sigma} = \frac{1}{N} \sum_{i=1}^N \hat{\sigma}_i$

$\tilde{\sigma}_i^B \equiv B \bar{\sigma} + (1-B) \hat{\sigma}_i$

```{r tildesigma, echo=FALSE, fig.width=4, fig.height=4}
bigpar(mar=c(5,6,1,1))
plot(sigma.hat, sigma.hat, asp=1,
     xlab=expression(hat(sigma[i])),
     ylab=expression(tilde(sigma)[i]^B))
cols <- c("purple","red","orange","green3")
for (i in 1:4) {
  B <- i/4 
  sigma.tilde <- B * mean(sigma.hat) + (1 - B) * sigma.hat
  points(sigma.hat, sigma.tilde, asp=1, col=cols[i])
}
```

---

### New estimator performance by rank
```{r roc2, echo=FALSE}
bigpar()
plot(curve(abs.t), type="o", pch=16, xlim=c(0,1), ylim=c(0,1))
for (i in 1:4) {
  B <- i/4 
  sigma.tilde <- B * mean(sigma.hat) + (1 - B) * sigma.hat
  new.t <- ts$dm / (sigma.tilde * sqrt(4/M))
  lines(curve(abs(new.t)), type="o", pch=16, col=cols[i])
}
legend("bottomright",paste0("B=",0:4/4),col=c("black",cols),pch=16,lty=1)
```

---

### Summary

* Top false positives were coming from genes with too low $\hat{\sigma}_i$
* Replace $\hat{\sigma}_i$ with an estimate which is closer to
  $\bar{\sigma}$
* Depending on "close", new estimator dominates at all thresholds

---

### How is this hierarchical?

Not your standard diagram, need to formalize

<img src="img/plate1.png">

---

### limma

* Smyth, G. K. (2004) Linear models and empirical Bayes methods for
assessing differential expression in microarray experiments 
[PDF](http://www.statsci.org/smyth/pubs/ebayes.pdf)
* Developed the hierarchical model introduced by Lonnstedt and Speed
  (2002) for single sample into method for any experiment represented
  as linear model

<br>

$$
\frac{1}{\sigma^2_i} \sim \frac{1}{d_0 \sigma_0^2} \chi_{d0}^2 
$$

<br>



---

### Why inverse $\chi^2$?

* Conjugacy provides closed form solution
* Posterior mean for $1/\sigma_i^2$ given $\hat{\sigma}_i^2$ is
  $1/\tilde{\sigma}_i^2$ with

<br>

$$
\tilde{\sigma}_i^2 = \frac{d_0 \hat{\sigma}_0^2 + d_i \hat{\sigma}_i^2}{d_0 + d_i} 
$$

And $d_i$ as the standard residual degrees of freedom

---

### Note that $d_0$ controls B

$$
\begin{align}
\tilde{\sigma}_i^2 &= \frac{d_0 \hat{\sigma}_0^2 + d_i
\hat{\sigma}_i^2}{d_0 + d_i}  \\
 &= \left( \frac{d_0}{d_0 + d_i} \right) \hat{\sigma}_0^2 +
\left( \frac{d_i}{d_0 + d_i} \right) \hat{\sigma}_i^2 \\
 &= B \hat{\sigma}_0^2 + (1-B) \hat{\sigma}_i^2
\end{align}
$$

---

### Proper hierarchical model

<img src="img/plate2.png">

---

### Estimation of hyperparameters

* Need to estimate $d_0, \hat{\sigma}_0^2$, which control strength and
location of *shrinkage* or *moderation*
* $d_0, \hat{\sigma}_0^2$ estimated via first two moments of $\log \hat{\sigma}_i^2$
* (Also need to estimate $\upsilon_{0}$, another parameter giving
  variance of coefficients)

---

### limma vs. naive estimators by rank

```{r echo=FALSE}
library(limma)
design <- model.matrix(~cond)
fit <- lmFit(X, design)
eb <- ebayes(fit)
limma.t <- eb$t[,2]
```

```{r roc3, echo=FALSE}
bigpar()
plot(curve(abs.t), type="o", pch=16, xlim=c(0,1), ylim=c(0,1))
for (i in 1:2) {
  B <- i/4
  sigma.tilde <- B * mean(sigma.hat) + (1 - B) * sigma.hat
  new.t <- ts$dm / (sigma.tilde * sqrt(4/M))
  lines(curve(abs(new.t)), type="o", pch=16, col=cols[i])
}
lines(curve(abs(limma.t)), type="o", pch=16, col="dodgerblue")
legend("bottomright",c(paste0("B=",0:2/4),"limma"),
       col=c("black",cols[1:2],"dodgerblue"),pch=16,lty=1)
```

---

### Rank is not the full picture

* The limma estimator is also estimating the degrees of freedom gained
  via the moderation

